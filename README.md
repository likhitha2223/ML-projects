# Project Repository

This repository contains code for clustering and classifying relations using various embedding models and machine learning techniques. It includes several tasks ranging from Set 1 clustering to classifying relations from the CoNLL04 dataset. Below is a detailed description of each folder and file in the repository.

## Repository Structure

### 1. `src` Folder

Contains six Python files for various tasks. Each task focuses on clustering or classification using relation embeddings.

- **`set1_data_clustering (iteration1).py`**: 
    - Takes the pre-defined relation clusters Excel file and Set 1 data Excel file from the `data` folder.
    - Assigns clusters to Set 1 relations by calculating the cosine similarity between the relation embedding and the mean embedding of each cluster.
    - Uses the `paraphrase-MiniLM-L6-v2` embedding model from the `transformers` library.
    - Saves the results as `new_cluster_results.xlsx` in the `output` folder.

- **`gpt4_relations_clustering (iteration2).py`**:
    - Uses the manually corrected clusters from iteration 1 and the GPT-generated extra relations Excel file.
    - Assigns each GPT-generated relation to the top 5 clusters based on cosine similarity.
    - Evaluates 5 different embedding models for this task, defined in the `configs/models.json` file.
    - Saves 5 different output files for each embedding model in the `output` folder.

- **`set2_mean_clustering (iteration3).py`**:
    - Takes the updated clusters from iteration 2 and the common ground truth/predicted Set 2 relations.
    - Assigns top 5 clusters to Set 2 relations based on the cosine similarity between the relation embedding and the mean embedding of each cluster.
    - Uses the `all-mpnet-base-v2` embedding model (as it gave the best results in iteration 2).

- **`set2_median_clustering (iteration3).py`**:
    - Similar to the previous task, but assigns clusters based on the **median embedding** of each cluster.

- **`set2_classification (iteration4).py`**:
    - Trains a random forest classifier on the embeddings from Set 1 and GPT-generated relations.
    - Predicts top 5 clusters for Set 2 relations based on the trained classifier.

- **`conll04_classification.py`**:
    - Applies random forest classification to classify relations from the CoNLL04 dataset based on their embeddings.

### 2. `scripts` Folder

Contains preprocessing code used before task 2 (iteration 2).

- **`set2_data_preprocessing.py`**:
    - Extracts common relations between the ground truth and predicted Set 2 relations.
    - Saves the processed data in an Excel file in the `output` folder.
    - This data is used as input for Set 2 mean/median clustering tasks.

### 3. `utils` Folder

Contains helper functions for various tasks in the repository.

- **`helpers.py`**: Functions for loading models, computing cosine similarities, and saving data.
- **`data_processing_utils.py`**: Functions for loading, processing, and extracting data.
- **`embedding_utils.py`**: Functions to create embeddings for clusters and relations.
- **`cluster_assignment_utils.py`**: Contains clustering functions (mean/median clustering and classification).
- **`evaluation_utils.py`**: Functions for evaluating the clustering results.
- **`model_utils.py`**: Functions to train and predict using random forest classifier.

### 4. `configs` Folder

Contains configuration files that define models and other parameters.

- **`models.json`**: 
    - Contains the 5 embedding models evaluated in task 2 (iteration 2).
    - Specifies the corresponding output Excel file names for each model.

### 5. `data` Folder

Stores all the input data files used across various tasks.

### 6. `output` Folder

Contains all output files generated by different tasks. These files include:

- Cluster assignment results for Set 1, GPT-generated relations, and Set 2 relations.
- Updated clusters based on mean/median clustering and classification tasks.

### 7. `requirements.txt` File

Contains all dependencies required to run the project. Install them using the following command:

```bash
pip install -r requirements.txt
